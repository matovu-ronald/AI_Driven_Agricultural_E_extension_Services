{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /opt/anaconda3/lib/python3.12/site-packages (0.8.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.12/site-packages (from tiktoken) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: einops in /opt/anaconda3/lib/python3.12/site-packages (0.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: accelerate in /opt/anaconda3/lib/python3.12/site-packages (0.33.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.12/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.12/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate) (2.3.0.post100)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate) (0.24.6)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate) (0.4.4)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (1.13.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting jsonlines\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jsonlines) (23.1.0)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Installing collected packages: jsonlines\n",
      "Successfully installed jsonlines-4.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken\n",
    "%pip install einops\n",
    "%pip install accelerate\n",
    "%pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "import itertools\n",
    "import torch\n",
    "\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0d/975d1jtj1v5692v1l52lsc5w0000gn/T/ipykernel_21088/2828159761.py:1: DtypeWarning: Columns (1,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  kcc_dataset = pd.read_csv('/Users/ronaldmatovu/Downloads/Kisan Call Centre/kcc_dataset.csv')\n"
     ]
    }
   ],
   "source": [
    "kcc_dataset = pd.read_csv('/Users/ronaldmatovu/Downloads/Kisan Call Centre/kcc_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first 1000 rows from the dataset\n",
    "kcc_dataset_1000 = kcc_dataset[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kcc_dataset_1000.to_csv('data/kcc_dataset_1000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kcc_dataset_1000 = pd.read_csv('data/kcc_dataset_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BlockName</th>\n",
       "      <th>Category</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Crop</th>\n",
       "      <th>DistrictName</th>\n",
       "      <th>QueryType</th>\n",
       "      <th>Season</th>\n",
       "      <th>Sector</th>\n",
       "      <th>StateName</th>\n",
       "      <th>QueryText</th>\n",
       "      <th>KccAns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1275</td>\n",
       "      <td>SAGAR</td>\n",
       "      <td>99</td>\n",
       "      <td>RABI</td>\n",
       "      <td>HORTICULTURE</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>how to control flower drop in bottelgourd</td>\n",
       "      <td>spray planofix4mlpump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>964</td>\n",
       "      <td>SAGAR</td>\n",
       "      <td>Disease Management</td>\n",
       "      <td>RABI</td>\n",
       "      <td>ANIMAL HUSBANDRY</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>how tyo control diseases in buffalo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1279</td>\n",
       "      <td>SAGAR</td>\n",
       "      <td>76</td>\n",
       "      <td>RABI</td>\n",
       "      <td>HORTICULTURE</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>how to control fruit borer in brinjal</td>\n",
       "      <td>should be spray profenophos 35mlpump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1064</td>\n",
       "      <td>SAGAR</td>\n",
       "      <td>3</td>\n",
       "      <td>RABI</td>\n",
       "      <td>AGRICULTURE</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>how to control of yellow moisac in moong</td>\n",
       "      <td>should be spray metasystox 35mlpump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1279</td>\n",
       "      <td>DAMOH</td>\n",
       "      <td>76</td>\n",
       "      <td>RABI</td>\n",
       "      <td>HORTICULTURE</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>how to control white fly in brinjal</td>\n",
       "      <td>should be spray metasystox 35mlpump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BlockName Category  Year  Month  Day  Crop DistrictName           QueryType  \\\n",
       "0      0           0  2006      1   17  1275        SAGAR                  99   \n",
       "1      0           0  2006      1   17   964        SAGAR  Disease Management   \n",
       "2      0           0  2006      1   17  1279        SAGAR                  76   \n",
       "3      0           0  2006      1   17  1064        SAGAR                   3   \n",
       "4      0           0  2006      1   17  1279        DAMOH                  76   \n",
       "\n",
       "  Season            Sector       StateName  \\\n",
       "0   RABI      HORTICULTURE  MADHYA PRADESH   \n",
       "1   RABI  ANIMAL HUSBANDRY  MADHYA PRADESH   \n",
       "2   RABI      HORTICULTURE  MADHYA PRADESH   \n",
       "3   RABI       AGRICULTURE  MADHYA PRADESH   \n",
       "4   RABI      HORTICULTURE  MADHYA PRADESH   \n",
       "\n",
       "                                   QueryText  \\\n",
       "0  how to control flower drop in bottelgourd   \n",
       "1        how tyo control diseases in buffalo   \n",
       "2      how to control fruit borer in brinjal   \n",
       "3   how to control of yellow moisac in moong   \n",
       "4        how to control white fly in brinjal   \n",
       "\n",
       "                                 KccAns  \n",
       "0                 spray planofix4mlpump  \n",
       "1                                   NaN  \n",
       "2  should be spray profenophos 35mlpump  \n",
       "3   should be spray metasystox 35mlpump  \n",
       "4   should be spray metasystox 35mlpump  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kcc_dataset_1000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kcc_dataset_1000 = kcc_dataset_1000.dropna()\n",
    "kcc_dataset_1000 = kcc_dataset_1000.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BlockName</th>\n",
       "      <th>Category</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Crop</th>\n",
       "      <th>DistrictName</th>\n",
       "      <th>QueryType</th>\n",
       "      <th>Season</th>\n",
       "      <th>Sector</th>\n",
       "      <th>StateName</th>\n",
       "      <th>QueryText</th>\n",
       "      <th>KccAns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1275</td>\n",
       "      <td>SAGAR</td>\n",
       "      <td>99</td>\n",
       "      <td>RABI</td>\n",
       "      <td>HORTICULTURE</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>how to control flower drop in bottelgourd</td>\n",
       "      <td>spray planofix4mlpump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1279</td>\n",
       "      <td>SAGAR</td>\n",
       "      <td>76</td>\n",
       "      <td>RABI</td>\n",
       "      <td>HORTICULTURE</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>how to control fruit borer in brinjal</td>\n",
       "      <td>should be spray profenophos 35mlpump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1064</td>\n",
       "      <td>SAGAR</td>\n",
       "      <td>3</td>\n",
       "      <td>RABI</td>\n",
       "      <td>AGRICULTURE</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>how to control of yellow moisac in moong</td>\n",
       "      <td>should be spray metasystox 35mlpump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1279</td>\n",
       "      <td>DAMOH</td>\n",
       "      <td>76</td>\n",
       "      <td>RABI</td>\n",
       "      <td>HORTICULTURE</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>how to control white fly in brinjal</td>\n",
       "      <td>should be spray metasystox 35mlpump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>DAMOH</td>\n",
       "      <td>3</td>\n",
       "      <td>RABI</td>\n",
       "      <td>AGRICULTURE</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>how to control termite in wheat</td>\n",
       "      <td>use chlorpyrephos1lithactwith the help of irri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BlockName Category  Year  Month  Day   Crop DistrictName QueryType Season  \\\n",
       "0      0           0  2006      1   17   1275        SAGAR        99   RABI   \n",
       "1      0           0  2006      1   17   1279        SAGAR        76   RABI   \n",
       "2      0           0  2006      1   17   1064        SAGAR         3   RABI   \n",
       "3      0           0  2006      1   17   1279        DAMOH        76   RABI   \n",
       "4      0           0  2006      1   17  Wheat        DAMOH         3   RABI   \n",
       "\n",
       "         Sector       StateName                                  QueryText  \\\n",
       "0  HORTICULTURE  MADHYA PRADESH  how to control flower drop in bottelgourd   \n",
       "1  HORTICULTURE  MADHYA PRADESH      how to control fruit borer in brinjal   \n",
       "2   AGRICULTURE  MADHYA PRADESH   how to control of yellow moisac in moong   \n",
       "3  HORTICULTURE  MADHYA PRADESH        how to control white fly in brinjal   \n",
       "4   AGRICULTURE  MADHYA PRADESH            how to control termite in wheat   \n",
       "\n",
       "                                              KccAns  \n",
       "0                              spray planofix4mlpump  \n",
       "1               should be spray profenophos 35mlpump  \n",
       "2                should be spray metasystox 35mlpump  \n",
       "3                should be spray metasystox 35mlpump  \n",
       "4  use chlorpyrephos1lithactwith the help of irri...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kcc_dataset_1000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "790"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kcc_dataset_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the QueryText and KccAns columns\n",
    "kcc_dataset_1000_QA = kcc_dataset_1000[['QueryText', 'KccAns']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 790 entries, 0 to 789\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   QueryText  790 non-null    object\n",
      " 1   KccAns     790 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 12.5+ KB\n"
     ]
    }
   ],
   "source": [
    "kcc_dataset_1000_QA.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QueryText</th>\n",
       "      <th>KccAns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how to control flower drop in bottelgourd</td>\n",
       "      <td>spray planofix4mlpump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how to control fruit borer in brinjal</td>\n",
       "      <td>should be spray profenophos 35mlpump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how to control of yellow moisac in moong</td>\n",
       "      <td>should be spray metasystox 35mlpump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how to control white fly in brinjal</td>\n",
       "      <td>should be spray metasystox 35mlpump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how to control termite in wheat</td>\n",
       "      <td>use chlorpyrephos1lithactwith the help of irri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>ASKED ABOUT THE CONTROL OF BPH</td>\n",
       "      <td>RECOMENDED TO SPRAY CARBORYL 3gm LIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>ASKED ABOUT THE CONTROL OF TOBACCO CATERPILLAR</td>\n",
       "      <td>RECOMENDED TO SPRAY CHLORIPYRIPOS 2MLLIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>ASKED ABOUT THE CONTROL OF WILT</td>\n",
       "      <td>RECOMMENDED TO DRAIN OUT WATER IMMEDIATLYRAISE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>ASKED ABOUT THE CONTROL OF SHEATH BLIGHT</td>\n",
       "      <td>RECOMMENDED TO SPRAY HEXACONAZOLE  2mllit OF W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>ASKED ABOUT THE CONTROL OF CANEFLIES</td>\n",
       "      <td>RECOMMENDED TO SPRAY ENDOSULPHAN 2 MLLIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>790 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          QueryText  \\\n",
       "0         how to control flower drop in bottelgourd   \n",
       "1             how to control fruit borer in brinjal   \n",
       "2          how to control of yellow moisac in moong   \n",
       "3               how to control white fly in brinjal   \n",
       "4                   how to control termite in wheat   \n",
       "..                                              ...   \n",
       "785                  ASKED ABOUT THE CONTROL OF BPH   \n",
       "786  ASKED ABOUT THE CONTROL OF TOBACCO CATERPILLAR   \n",
       "787                 ASKED ABOUT THE CONTROL OF WILT   \n",
       "788        ASKED ABOUT THE CONTROL OF SHEATH BLIGHT   \n",
       "789            ASKED ABOUT THE CONTROL OF CANEFLIES   \n",
       "\n",
       "                                                KccAns  \n",
       "0                                spray planofix4mlpump  \n",
       "1                 should be spray profenophos 35mlpump  \n",
       "2                  should be spray metasystox 35mlpump  \n",
       "3                  should be spray metasystox 35mlpump  \n",
       "4    use chlorpyrephos1lithactwith the help of irri...  \n",
       "..                                                 ...  \n",
       "785               RECOMENDED TO SPRAY CARBORYL 3gm LIT  \n",
       "786           RECOMENDED TO SPRAY CHLORIPYRIPOS 2MLLIT  \n",
       "787  RECOMMENDED TO DRAIN OUT WATER IMMEDIATLYRAISE...  \n",
       "788  RECOMMENDED TO SPRAY HEXACONAZOLE  2mllit OF W...  \n",
       "789           RECOMMENDED TO SPRAY ENDOSULPHAN 2 MLLIT  \n",
       "\n",
       "[790 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kcc_dataset_1000_QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kcc_dataset_1000_QA.to_csv('data/kcc_dataset_1000_QA.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a padding token to the tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input texts\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['QueryText'], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains split the data into training and validation sets with names (train_data and val_data)\n",
    "# Path to the dataset: data/kcc_dataset_1000_QA.csv\n",
    "\n",
    "dataset = pd.read_csv('data/kcc_dataset_1000_QA.csv')\n",
    "\n",
    "# Filter rows with non-null answers\n",
    "dataset_filtered = dataset.dropna(subset=['KccAns'])\n",
    "\n",
    "# Select relevant columns for QA task\n",
    "qa_dataset = dataset_filtered[['QueryText', 'KccAns']]\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data, val_data = train_test_split(qa_dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f9c48286e1487db410ffa5ef0b367c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a068d7ef1f9c4b37b90f4f18a6e4096e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.6706137657165527, 'eval_runtime': 3.8583, 'eval_samples_per_second': 40.951, 'eval_steps_per_second': 20.475, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results_gpt2/checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5819, 'learning_rate': 1.6835443037974685e-05, 'epoch': 1.58}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c35854a61a843e38faeafa1bbecd080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.189133167266846, 'eval_runtime': 4.1351, 'eval_samples_per_second': 38.21, 'eval_steps_per_second': 19.105, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546c3c8fb1c342d6a0324e3a065c490a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.609767198562622, 'eval_runtime': 3.7344, 'eval_samples_per_second': 42.309, 'eval_steps_per_second': 21.155, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results_gpt2/checkpoint-1000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2049, 'learning_rate': 1.3670886075949368e-05, 'epoch': 3.16}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d61b962af44c57b2840dbedfc8f5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.448578357696533, 'eval_runtime': 3.9929, 'eval_samples_per_second': 39.57, 'eval_steps_per_second': 19.785, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results_gpt2/checkpoint-1500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1754, 'learning_rate': 1.0506329113924052e-05, 'epoch': 4.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b1a27aec704e8dbc991369767de870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.528191089630127, 'eval_runtime': 3.8458, 'eval_samples_per_second': 41.084, 'eval_steps_per_second': 20.542, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025fb587cde34840a7a4ba3b816e1471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.972825527191162, 'eval_runtime': 3.6773, 'eval_samples_per_second': 42.966, 'eval_steps_per_second': 21.483, 'epoch': 6.0}\n",
      "{'loss': 0.0909, 'learning_rate': 7.341772151898735e-06, 'epoch': 6.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f991d7e7f444bf95dbe9b5c937b18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.144602298736572, 'eval_runtime': 3.6673, 'eval_samples_per_second': 43.084, 'eval_steps_per_second': 21.542, 'epoch': 7.0}\n",
      "{'loss': 0.0825, 'learning_rate': 4.177215189873418e-06, 'epoch': 7.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9dabe12c0d41c6921023dfa91c5fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.964780807495117, 'eval_runtime': 3.6691, 'eval_samples_per_second': 43.063, 'eval_steps_per_second': 21.531, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c817bc34ac449d7b525bb6d6141a17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.042965888977051, 'eval_runtime': 3.7015, 'eval_samples_per_second': 42.686, 'eval_steps_per_second': 21.343, 'epoch': 9.0}\n",
      "{'loss': 0.0623, 'learning_rate': 1.0126582278481013e-06, 'epoch': 9.49}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d728f194e4de462ea05fba03a5a897df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.872794151306152, 'eval_runtime': 3.6345, 'eval_samples_per_second': 43.473, 'eval_steps_per_second': 21.736, 'epoch': 10.0}\n",
      "{'train_runtime': 833.3253, 'train_samples_per_second': 7.584, 'train_steps_per_second': 3.792, 'train_loss': 0.19197217286387577, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13db2bf0c5ed45f1849b30c97f41ea32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.834618091583252, 'eval_runtime': 3.576, 'eval_samples_per_second': 44.183, 'eval_steps_per_second': 22.092, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./models/gpt2_fine_tuned/tokenizer_config.json',\n",
       " './models/gpt2_fine_tuned/special_tokens_map.json',\n",
       " './models/gpt2_fine_tuned/vocab.json',\n",
       " './models/gpt2_fine_tuned/merges.txt',\n",
       " './models/gpt2_fine_tuned/added_tokens.json')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Add a padding token to the tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Tokenize the input texts\n",
    "def tokenize_function(example):\n",
    "    input_text = example['QueryText'] + \" \" + tokenizer.eos_token + \" \" + example['KccAns']\n",
    "    inputs = tokenizer(input_text, truncation=True, padding='max_length', max_length=128)\n",
    "    inputs['labels'] = inputs.input_ids.copy()  # Set labels to be the same as input_ids\n",
    "    return inputs\n",
    "\n",
    "# Tokenize the training and validation data\n",
    "train_encodings = train_data.apply(tokenize_function, axis=1).tolist()\n",
    "val_encodings = val_data.apply(tokenize_function, axis=1).tolist()\n",
    "\n",
    "# Prepare datasets\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val) for key, val in self.encodings[idx].items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)\n",
    "\n",
    "train_dataset = QADataset(train_encodings)\n",
    "val_dataset = QADataset(val_encodings)\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results_gpt2',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "metrics_gpt2 = trainer.evaluate()\n",
    "print(metrics_gpt2)\n",
    "\n",
    "# Save the fine-tuned model and tokenizer\n",
    "model_save_path = './models/gpt2_fine_tuned'\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How to control fruit borer in brinjal?\n",
      "Answer: How to control fruit borer in brinjal?\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_save_path = './models/gpt2_fine_tuned'  # Path to the saved model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_save_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_save_path)\n",
    "\n",
    "# Add a padding token to the tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_answer(question, max_length=50):\n",
    "    # Tokenize the input question\n",
    "    inputs = tokenizer.encode(question, return_tensors='pt')\n",
    "    \n",
    "    # Generate the answer\n",
    "    outputs = model.generate(inputs, max_length=max_length, pad_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "    # Decode the generated answer\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return answer\n",
    "\n",
    "# Example question\n",
    "question = \"How to control fruit borer in brinjal?\"\n",
    "\n",
    "# Generate the answer\n",
    "answer = generate_answer(question)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to control weed in field and field is the best to control weed in field and field is the best to control weed in field and field is the best to control weed in field and field is the best to control weed in field and field is the\n"
     ]
    }
   ],
   "source": [
    "print(generate_answer(\"how to control weed in field\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: how to control flower drop in bottelgourd Answer: spray planofix4mlpump'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = kcc_dataset_1000_QA.to_dict()\n",
    "text = \"Question: \" + examples[\"QueryText\"][0] + \" Answer: \" + examples[\"KccAns\"][0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'should be spray metasystox 35mlpump'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[\"KccAns\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_qa = \"\"\"### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\n",
    "{answer}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Question:\\nhow to control flower drop in bottelgourd\\n\\n### Answer:\\nspray planofix4mlpump'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = examples[\"QueryText\"][0]\n",
    "answer = examples[\"KccAns\"][0]\n",
    "\n",
    "text_with_prompt_template = prompt_template_qa.format(question=question, answer=answer)\n",
    "text_with_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_q = \"\"\"### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "790"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the total number of examples in the dataset.\n",
    "num_examples = len(examples[\"QueryText\"])\n",
    "num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_dataset_text_only = []\n",
    "finetuning_dataset_question_answer = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_examples):\n",
    "    question = examples[\"QueryText\"][i]\n",
    "    answer = examples[\"KccAns\"][i]\n",
    "\n",
    "    text_with_prompt_template_qa = prompt_template_qa.format(question=question, answer=answer)\n",
    "    finetuning_dataset_text_only.append({\"text\": text_with_prompt_template_qa})\n",
    "\n",
    "    text_with_prompt_template_q = prompt_template_q.format(question=question)\n",
    "    finetuning_dataset_question_answer.append({\"question\": text_with_prompt_template_q, \"answer\": answer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '### Question:\\nhow to control flower drop in bottelgourd\\n\\n### Answer:\\nspray planofix4mlpump'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuning_dataset_text_only[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '### Question:\\nhow to control flower drop in bottelgourd\\n\\n### Answer:',\n",
       " 'answer': 'spray planofix4mlpump'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuning_dataset_question_answer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open(f\"data/kcc_qa_processed.jsonl\", \"w\") as writer:\n",
    "    writer.write_all(finetuning_dataset_question_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e6e344208e4ffb896c7534e252bdb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac09cc7a61848ce81659feb11b439ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6bf7c1ca3b4305ac3af39ae6f74ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finetuning_dataset = load_dataset('json', data_files='data/kcc_qa_processed.jsonl', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questio-Answer-fine-tuned dataset:\n",
      "{'question': '### Question:\\nhow to control flower drop in bottelgourd\\n\\n### Answer:', 'answer': 'spray planofix4mlpump'}\n",
      "{'question': '### Question:\\nhow to control fruit borer in brinjal\\n\\n### Answer:', 'answer': 'should be spray profenophos 35mlpump'}\n",
      "{'question': '### Question:\\nhow to control of yellow moisac in moong\\n\\n### Answer:', 'answer': 'should be spray metasystox 35mlpump'}\n",
      "{'question': '### Question:\\nhow to control white fly in brinjal\\n\\n### Answer:', 'answer': 'should be spray metasystox 35mlpump'}\n",
      "{'question': '### Question:\\nhow to control termite in wheat\\n\\n### Answer:', 'answer': 'use chlorpyrephos1lithactwith the help of irrigation'}\n"
     ]
    }
   ],
   "source": [
    "m = 5\n",
    "print(\"Questio-Answer-fine-tuned dataset:\")\n",
    "top_m = list(itertools.islice(finetuning_dataset, m))\n",
    "for j in top_m:\n",
    "  print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the juypter notebook commons/common_functions.ipynb\n",
    "%run commons/common_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One datapoint in the finetuning dataset:\n",
      "{'answer': 'spray planofix4mlpump',\n",
      " 'question': '### Question:\\n'\n",
      "             '### Question:\\n'\n",
      "             'how to control flower drop in bottelgourd\\n'\n",
      "             '\\n'\n",
      "             '### Answer:\\n'\n",
      "             '\\n'\n",
      "             '### Answer:'}\n"
     ]
    }
   ],
   "source": [
    "filename = \"data/kcc_qa_processed.jsonl\"\n",
    "instruction_dataset_df = pd.read_json(filename, lines=True)\n",
    "examples = instruction_dataset_df.to_dict()\n",
    "\n",
    "if \"question\" in examples and \"answer\" in examples:\n",
    "  text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
    "elif \"instruction\" in examples and \"response\" in examples:\n",
    "  text = examples[\"instruction\"][0] + examples[\"response\"][0]\n",
    "elif \"input\" in examples and \"output\" in examples:\n",
    "  text = examples[\"input\"][0] + examples[\"output\"][0]\n",
    "else:\n",
    "  text = examples[\"text\"][0]\n",
    "\n",
    "prompt_template = \"\"\"### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\"\"\"\n",
    "\n",
    "num_examples = len(examples[\"question\"])\n",
    "finetuning_dataset = []\n",
    "for i in range(num_examples):\n",
    "  question = examples[\"question\"][i]\n",
    "  answer = examples[\"answer\"][i]\n",
    "  text_with_prompt_template = prompt_template.format(question=question)\n",
    "  finetuning_dataset.append({\"question\": text_with_prompt_template, \"answer\": answer})\n",
    "\n",
    "from pprint import pprint\n",
    "print(\"One datapoint in the finetuning dataset:\")\n",
    "pprint(finetuning_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    if \"question\" in examples and \"answer\" in examples:\n",
    "      text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
    "    elif \"input\" in examples and \"output\" in examples:\n",
    "      text = examples[\"input\"][0] + examples[\"output\"][0]\n",
    "    else:\n",
    "      text = examples[\"text\"][0]\n",
    "\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    max_length = min(\n",
    "        tokenized_inputs[\"input_ids\"].shape[1],\n",
    "        2048\n",
    "    )\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c88dfb4e60a441da84a9d442c4a8940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/790 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 790\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "finetuning_dataset_loaded = datasets.load_dataset(\"json\", data_files=filename, split=\"train\")\n",
    "\n",
    "tokenized_dataset = finetuning_dataset_loaded.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    "    drop_last_batch=True\n",
    ")\n",
    "\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.add_column(\"labels\", tokenized_dataset[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 711\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 79\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, shuffle=True, seed=123)\n",
    "print(split_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    \"model\": {\n",
    "        \"pretrained_name\": model_name,\n",
    "        \"max_length\" : 2048\n",
    "    },\n",
    "    \"datasets\": {\n",
    "        \"use_hf\": True,\n",
    "        \"path\": split_dataset\n",
    "    },\n",
    "    \"verbose\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: {'question': '### Question:\\nwhat are control of cow pea mosaic \\n\\n### Answer:', 'answer': 'spray trizophose  30 ml pump', 'input_ids': [21017, 18233, 25, 198, 10919, 389, 1630, 286, 9875, 613, 64, 47076, 220, 198, 198, 21017, 23998, 25, 34975, 323, 1333, 89, 2522, 577, 220, 1542, 25962, 8901], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [21017, 18233, 25, 198, 10919, 389, 1630, 286, 9875, 613, 64, 47076, 220, 198, 198, 21017, 23998, 25, 34975, 323, 1333, 89, 2522, 577, 220, 1542, 25962, 8901]}\n",
      "Test dataset: {'question': '### Question:\\nASKED ABOUT CONTROL FOR WEEDS\\n\\n### Answer:', 'answer': 'RECOMMENDED TO SPRAY PENDIMETHYLIN 15LTACRE', 'input_ids': [21017, 18233, 25, 198, 1921, 42, 1961, 33478, 49833, 7473, 12887, 1961, 50, 198, 198, 21017, 23998, 25, 2200, 9858, 44, 49361, 5390, 6226, 30631, 350, 10619, 3955, 20702, 56, 34509, 1315, 27734, 2246, 2200], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [21017, 18233, 25, 198, 1921, 42, 1961, 33478, 49833, 7473, 12887, 1961, 50, 198, 198, 21017, 23998, 25, 2200, 9858, 44, 49361, 5390, 6226, 30631, 350, 10619, 3955, 20702, 56, 34509, 1315, 27734, 2246, 2200]}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = split_dataset[\"train\"]\n",
    "test_dataset = split_dataset[\"test\"]\n",
    "print(\"Train dataset:\", train_dataset[0])\n",
    "print(\"Test dataset:\", test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "global_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_count = torch.cuda.device_count()\n",
    "if device_count > 0:\n",
    "    logger.debug(\"Select GPU device\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    logger.debug(\"Select CPU device\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
    "  # Tokenize\n",
    "  input_ids = tokenizer.encode(\n",
    "          text,\n",
    "          return_tensors=\"pt\",\n",
    "          truncation=True,\n",
    "          max_length=max_input_tokens\n",
    "  )\n",
    "\n",
    "  # Generate\n",
    "  device = model.device\n",
    "  generated_tokens_with_prompt = model.generate(\n",
    "    input_ids=input_ids.to(device),\n",
    "    max_length=max_output_tokens\n",
    "  )\n",
    "\n",
    "  # Decode\n",
    "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "  # Strip the prompt\n",
    "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
    "\n",
    "  return generated_text_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question input (test): ### Question:\n",
      "ASKED ABOUT CONTROL FOR WEEDS\n",
      "\n",
      "### Answer:\n",
      "Correct answer from Lamini docs: RECOMMENDED TO SPRAY PENDIMETHYLIN 15LTACRE\n",
      "Model's answer: \n",
      "\n",
      "\n",
      "The problem with the \"control\" of weeds is that they are not controlled by the environment. They are controlled by the environment.\n",
      "\n",
      "The problem with the \"control\" of weeds is that they are not controlled by the environment. They are controlled by the environment.\n",
      "\n",
      "The problem with the \"control\" of weeds is that they are not controlled by the environment. They are controlled by the\n"
     ]
    }
   ],
   "source": [
    "test_text = test_dataset[0]['question']\n",
    "print(\"Question input (test):\", test_text)\n",
    "print(f\"Correct answer from Lamini docs: {test_dataset[0]['answer']}\")\n",
    "print(\"Model's answer: \")\n",
    "print(inference(test_text, base_model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_name = f\"gpt2_{max_steps}_steps\"\n",
    "output_dir = trained_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import TrainingArguments\n",
    "from transformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "\n",
    "  # Learning rate\n",
    "  learning_rate=1.0e-5,\n",
    "\n",
    "  # Number of training epochs\n",
    "  num_train_epochs=100,\n",
    "\n",
    "  # Max steps to train for (each step is a batch of data)\n",
    "  # Overrides num_train_epochs, if not -1\n",
    "  max_steps=max_steps,\n",
    "\n",
    "  # Batch size for training\n",
    "  per_device_train_batch_size=1,\n",
    "\n",
    "  # Directory to save model checkpoints\n",
    "  output_dir=output_dir,\n",
    "\n",
    "  # Other arguments\n",
    "  overwrite_output_dir=False, # Overwrite the content of the output directory\n",
    "  disable_tqdm=False, # Disable progress bars\n",
    "  eval_steps=120, # Number of update steps between two evaluations\n",
    "  save_steps=120, # After # steps model is saved\n",
    "  warmup_steps=1, # Number of warmup steps for learning rate scheduler\n",
    "  per_device_eval_batch_size=1, # Batch size for evaluation\n",
    "  evaluation_strategy=\"steps\",\n",
    "  logging_strategy=\"steps\",\n",
    "  logging_steps=1,\n",
    "  optim=\"adafactor\",\n",
    "  gradient_accumulation_steps = 4,\n",
    "  gradient_checkpointing=False,\n",
    "\n",
    "  # Parameters for early stopping\n",
    "  load_best_model_at_end=True,\n",
    "  save_total_limit=1,\n",
    "  metric_for_best_model=\"eval_loss\",\n",
    "  greater_is_better=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n",
      "Memory footprint 0.510342192 GB\n",
      "Flops 4180.672512 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "model_flops = (\n",
    "  base_model.floating_point_ops(\n",
    "    {\n",
    "       \"input_ids\": torch.zeros(\n",
    "           (1, training_config[\"model\"][\"max_length\"])\n",
    "      )\n",
    "    }\n",
    "  )\n",
    "  * training_args.gradient_accumulation_steps\n",
    ")\n",
    "\n",
    "print(base_model)\n",
    "print(\"Memory footprint\", base_model.get_memory_footprint() / 1e9, \"GB\")\n",
    "print(\"Flops\", model_flops / 1e9, \"GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "trainer = Trainer(\n",
    "    model=base_model,\n",
    "    # model_flops=model_flops,\n",
    "    # total_steps=max_steps,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b961e5677d746d5a15da606afd9ffc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6347, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 3.0602, 'learning_rate': 5e-06, 'epoch': 0.01}\n",
      "{'loss': 3.1144, 'learning_rate': 0.0, 'epoch': 0.02}\n",
      "{'train_runtime': 2.6305, 'train_samples_per_second': 4.562, 'train_steps_per_second': 1.14, 'train_loss': 3.26977809270223, 'epoch': 0.02}\n"
     ]
    }
   ],
   "source": [
    "training_output = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: gpt2_3_steps/final\n"
     ]
    }
   ],
   "source": [
    "save_dir = f'{output_dir}/final'\n",
    "\n",
    "trainer.save_model(save_dir)\n",
    "print(\"Saved model to:\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_slightly_model = AutoModelForCausalLM.from_pretrained(save_dir, local_files_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_slightly_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question input (test): ### Question:\n",
      "ASKED ABOUT CONTROL FOR WEEDS\n",
      "\n",
      "### Answer:\n",
      "Finetuned slightly model's answer: \n",
      "\n",
      "\n",
      "### Answer:\n",
      "\n",
      "### Answer:\n",
      "\n",
      "### Answer:\n",
      "\n",
      "### Answer:\n",
      "\n",
      "### Answer:\n",
      "\n",
      "### Answer:\n",
      "\n",
      "### Answer:\n",
      "\n",
      "### Answer:\n",
      "\n",
      "### Answer:\n",
      "\n",
      "### Answer:\n",
      "\n",
      "### Answer:\n",
      "\n",
      "### Answer:\n",
      "\n",
      "### Answer:\n",
      "\n",
      "### Answer:\n",
      "\n",
      "### Answer:\n",
      "\n",
      "### Answer:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_question = test_dataset[0]['question']\n",
    "print(\"Question input (test):\", test_question)\n",
    "\n",
    "print(\"Finetuned slightly model's answer: \")\n",
    "print(inference(test_question, finetuned_slightly_model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target answer output (test): RECOMMENDED TO SPRAY PENDIMETHYLIN 15LTACRE\n"
     ]
    }
   ],
   "source": [
    "test_answer = test_dataset[0]['answer']\n",
    "print(\"Target answer output (test):\", test_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_hf = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    \"model\": {\n",
    "        \"pretrained_name\": model_name,\n",
    "        \"max_length\" : 2048\n",
    "    },\n",
    "    \"datasets\": {\n",
    "        \"use_hf\": use_hf,\n",
    "        \"path\": finetuning_dataset\n",
    "    },\n",
    "    \"verbose\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Question:\\nhow to control flower drop in bottelgourd\\n\\n### Answer:'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_question = finetuning_dataset[0][\"question\"]\n",
    "test_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Question:\n",
      "how to control flower drop in bottelgourd\n",
      "\n",
      "### Answer:\n",
      "\n",
      "\n",
      "The flower drop is a very important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part of the flower. It is the most important part\n"
     ]
    }
   ],
   "source": [
    "test_question = finetuning_dataset[0][\"question\"]\n",
    "generated_answer = model_inference(test_question, model, tokenizer)\n",
    "print(test_question)\n",
    "print(generated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9de6203e8441e69407a9be8ee859e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430d4a1b62f5479da797bcf1d16bb51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    offload_folder=\"save_folder\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepset/roberta-base-squad2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 790\n",
       "})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuning_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '### Question:\\nhow to control flower drop in bottelgourd\\n\\n### Answer:',\n",
       " 'answer': 'spray planofix4mlpump'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_qa = finetuning_dataset[0]\n",
    "sample_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aunchancyania CSV numericalagne tattancy STEPancy CSV numericalensenensen STEP numericalensenensen STEP numericalensen STEP numericalensen STEPensenancy CSV numericalagne CSV numericalagneancyrity Jurassicensen CSV numericalagneancy CSVancyusionsusionsagne CSVancyusionsancyusionsancyusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusions rinkremlinurations STEPapoancy CSVagne Daneagne STEPapo realitiesagne CSV CSVagneancyagne STEP CSVagne CSV CSV spaambersambersagne CSV CSV CSVagneagneagne rocking STATS CSVagneancyagne CSV CSVagne paddedagne STEP CSVagne padded padded CSV realitiesremlinagne rink STATS CSVagne RESTagneereo STATSOTT STATS realities STATS realities STATS realities STATS realities STATS realitiesrity realities realities realities realitiesagne STATS realities STATS realities STATS realities rink STATS realities rink STATS realitiesagne STATSagneambers STATS realitiesagne realities Realityagneancyusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsancyusionsusionsancyusionsancyusionsancyusionsusionsusionsusionsusionsusionsusionsusionsusionsancyusions descriptoragne rinkagneereoagne RESTOTTancy realitiesagneagne rink STATSOTT STATSOTT STATS realities realities realities realitiesPredambersambersambersraseambersrase STEP realitiesagne realities realities realities realitiesPred realitiesECK STATS realitiesagneambersraseambersambersancyancyambersraseancyancyambersraseriminationancyancyambersraseancyancyancyusionsraseriminationancyancyusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsrealityremlinusionsancyusionsrealityrealityremlinusionsrealityrealityancyusionsrealityrealityrealityrealityrealityrealityrealityrealityrealityrealityrealityrealityancyusionsrealityancyusionsrealityancyusions descriptoragneancyusionsrealityancyusions descriptoragneriminationrealityancyusionsrealityreality impedanceancyusionsagneagnerimination decimalagne disabilityagneriminationrealityrealityrealityrealityrealityrealityrealityrealityrealityrealityrealityrealityrealityrealityrealityrealityrealityrealityrealityrealityrealityrealityrealityrealityrealityancyusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusionsusions\n"
     ]
    }
   ],
   "source": [
    "print(model_inference(sample_qa[\"question\"], model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

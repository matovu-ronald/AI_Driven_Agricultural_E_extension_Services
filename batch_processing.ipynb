{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv('data/EDA_outputs/kcc_dataset_QA_cleaned_60K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QueryText</th>\n",
       "      <th>KccAns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GROUNDNUT VERITIES</td>\n",
       "      <td>GROUNDNUT VERITIES -TAG 24 TG 26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASKED ABOUT SOWING TIME OF GROUND NUT</td>\n",
       "      <td>SOWING TIME OF GROUND NUT-IT GENERALLY CULTIVA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TELL ME CONTROL LAT IN GROUNDNUT</td>\n",
       "      <td>SPRAY OF PROFENOFOS 15 ML PER LITER WATER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weed management in groundnut</td>\n",
       "      <td>hand weeding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Farmer wants to know about fungal disease mana...</td>\n",
       "      <td>--                -</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           QueryText  \\\n",
       "0                                 GROUNDNUT VERITIES   \n",
       "1              ASKED ABOUT SOWING TIME OF GROUND NUT   \n",
       "2                   TELL ME CONTROL LAT IN GROUNDNUT   \n",
       "3                       weed management in groundnut   \n",
       "4  Farmer wants to know about fungal disease mana...   \n",
       "\n",
       "                                              KccAns  \n",
       "0                   GROUNDNUT VERITIES -TAG 24 TG 26  \n",
       "1  SOWING TIME OF GROUND NUT-IT GENERALLY CULTIVA...  \n",
       "2          SPRAY OF PROFENOFOS 15 ML PER LITER WATER  \n",
       "3                                       hand weeding  \n",
       "4                                --                -  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch file 'batches/batch_tasks_queries_1.jsonl' created successfully.\n",
      "Batch file 'batches/batch_tasks_queries_2.jsonl' created successfully.\n",
      "Batch file 'batches/batch_tasks_queries_3.jsonl' created successfully.\n",
      "Batch file 'batches/batch_tasks_queries_4.jsonl' created successfully.\n",
      "Batch file 'batches/batch_tasks_queries_5.jsonl' created successfully.\n",
      "Batch file 'batches/batch_tasks_queries_6.jsonl' created successfully.\n",
      "Batch file 'batches/batch_tasks_queries_7.jsonl' created successfully.\n",
      "Batch file 'batches/batch_tasks_queries_8.jsonl' created successfully.\n",
      "Batch file 'batches/batch_tasks_queries_9.jsonl' created successfully.\n",
      "Batch file 'batches/batch_tasks_queries_10.jsonl' created successfully.\n",
      "Batch file 'batches/batch_tasks_queries_11.jsonl' created successfully.\n",
      "Batch file 'batches/batch_tasks_queries_12.jsonl' created successfully.\n",
      "Batch file 'batches/batch_tasks_queries_13.jsonl' created successfully.\n",
      "Batch file 'batches/batch_tasks_queries_14.jsonl' created successfully.\n",
      "Batch file 'batches/batch_tasks_queries_15.jsonl' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Configuration for splitting into smaller batches\n",
    "batch_size = 6000  # Adjust the batch size based on your limit and data size\n",
    "batch_number = 1\n",
    "batch_dir = \"batches\"\n",
    "\n",
    "# Create a directory to store the batch files\n",
    "if not os.path.exists(batch_dir):\n",
    "    os.makedirs(batch_dir)\n",
    "\n",
    "for start in range(0, len(df), batch_size):\n",
    "    end = start + batch_size\n",
    "    batch_df = df[start:end]\n",
    "    \n",
    "    # Create the JSONL batch file\n",
    "    batch_tasks = []\n",
    "\n",
    "    for index, row in batch_df.iterrows():\n",
    "        question = row['QueryText']\n",
    "        answer = row['KccAns']\n",
    "        task = {\n",
    "            \"custom_id\": f\"task-{start + index}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": \"gpt-4o-mini\",\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that corrects grammar while preserving the original meaning.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Correct the grammar of the following answer based on the question '{question}', maintaining its original meaning. Use lowercase letters. In case the answer is empty or has symbols and numbers, provide a suitable answer to the farmer's question: '{answer}'\"}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        batch_tasks.append(task)\n",
    "\n",
    "    # Write the tasks to a .jsonl file\n",
    "    batch_file_name = os.path.join(batch_dir, f\"batch_tasks_queries_{batch_number}.jsonl\")\n",
    "\n",
    "    with open(batch_file_name, 'w') as file:\n",
    "        for task in batch_tasks:\n",
    "            file.write(json.dumps(task) + '\\n')\n",
    "\n",
    "    print(f\"Batch file '{batch_file_name}' created successfully.\")\n",
    "    batch_number += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch file 'batch_tasks_queries.jsonl' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create the JSONL batch file\n",
    "batch_tasks = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    question = row['QueryText']\n",
    "    answer = row['KccAns']\n",
    "    task = {\n",
    "        \"custom_id\": f\"task-{index}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that corrects grammar while preserving the original meaning.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Correct the grammar of the following answer based on the question '{question}', maintaining its original meaning. Use lowercase letters. In case the answer is empty or has symbols and numbers, provide a suitable answer to the farmer's question: '{answer}'\"}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    batch_tasks.append(task)\n",
    "\n",
    "# Write the tasks to a .jsonl file\n",
    "file_name = \"batch_tasks_queries.jsonl\"\n",
    "\n",
    "with open(file_name, 'w') as file:\n",
    "    for task in batch_tasks:\n",
    "        file.write(json.dumps(task) + '\\n')\n",
    "\n",
    "print(f\"Batch file '{file_name}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"custom_id\": \"task-0\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-4o-mini\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant that corrects grammar while preserving the original meaning.\"}, {\"role\": \"user\", \"content\": \"Correct the grammar of the following answer based on the question 'GROUNDNUT VERITIES', maintaining its original meaning. Use lowercase letters. In case the answer is empty or has symbols and numbers, provide a suitable answer to the farmer's question: 'GROUNDNUT VERITIES -TAG 24 TG 26'\"}]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory paths for input and output files\n",
    "batches_dir = \"batches/\"\n",
    "outputs_dir = \"batches/outputs/\"\n",
    "data_dir = \"data/\"\n",
    "output_file = os.path.join(data_dir, \"kcc_dataset_QA_cleaned_60K_grammar_improved.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read both input and output JSONL files using pandas\n",
    "def read_files(file_names):\n",
    "    data = []\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            # Read each file as a DataFrame and convert it to a list of dictionaries\n",
    "            df = pd.read_json(file_name, lines=True)\n",
    "            data.append(df)\n",
    "            print(f\"Successfully loaded {file_name}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping file {file_name} due to error: {e}\")\n",
    "    # Concatenate all data into a single DataFrame if there is data\n",
    "    if data:\n",
    "        return pd.concat(data, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# List of input file names\n",
    "input_file_names = [\n",
    "    \"batches/batch_tasks_queries_1.jsonl\",\n",
    "    \"batches/batch_tasks_queries_2.jsonl\",\n",
    "    \"batches/batch_tasks_queries_3.jsonl\",\n",
    "    \"batches/batch_tasks_queries_4.jsonl\",\n",
    "    \"batches/batch_tasks_queries_5.jsonl\",\n",
    "    \"batches/batch_tasks_queries_6.jsonl\",\n",
    "    \"batches/batch_tasks_queries_7.jsonl\",\n",
    "    \"batches/batch_tasks_queries_8.jsonl\",\n",
    "    \"batches/batch_tasks_queries_9.jsonl\",\n",
    "    \"batches/batch_tasks_queries_10.jsonl\",\n",
    "    \"batches/batch_tasks_queries_11.jsonl\",\n",
    "    \"batches/batch_tasks_queries_12.jsonl\",\n",
    "    \"batches/batch_tasks_queries_13.jsonl\",\n",
    "    \"batches/batch_tasks_queries_14.jsonl\",\n",
    "    \"batches/batch_tasks_queries_15.jsonl\"\n",
    "]\n",
    "\n",
    "# List of output file names\n",
    "output_file_names = [\n",
    "    \"batches/outputs/1_batch_PoC7eDs9NQBh7fjeU24oPLbj_output.jsonl\",\n",
    "    \"batches/outputs/2_batch_TtqZkmGuJkvBiDMFlnfYrz26_output.jsonl\",\n",
    "    \"batches/outputs/3_batch_CD1D0C8yA7pD8B3Lii8hS80E_output.jsonl\",\n",
    "    \"batches/outputs/4_batch_zxAevbs0cwwEArQ6ehIhpxo2_output.jsonl\",\n",
    "    \"batches/outputs/5_batch_fmBtKML1oXWpEgt1Wwwe9tEf_output.jsonl\",\n",
    "    \"batches/outputs/6_batch_FWgAv510sVRhDmbwYquOtpnF_output.jsonl\",\n",
    "    \"batches/outputs/7_batch_Pj2nb7ICOeH3tDX044ZvyXeS_output.jsonl\",\n",
    "    \"batches/outputs/8_batch_KWDRxZD0l9HNeFIXeAShabFQ_output.jsonl\",\n",
    "    \"batches/outputs/9_batch_0MTrNU0cmxgodLvYKsXK8VON_output.jsonl\",\n",
    "    \"batches/outputs/10_batch_7g0csgkSanQPM2sE3EOTo9yc_output.jsonl\",\n",
    "    \"batches/outputs/11_batch_KOp7vbxMAYa6rXyYOizUfVel_output.jsonl\",\n",
    "    \"batches/outputs/12_batch_yMPPBChPtn5y3QcrhshpMH5O_output.jsonl\",\n",
    "    \"batches/outputs/13_batch_bpZzVjOPDXAxL8ISaKK2Bn1N_output.jsonl\",\n",
    "    \"batches/outputs/14_batch_oZREwstzByDley0gFHgPtIVp_output.jsonl\",\n",
    "    \"batches/outputs/15_batch_BFHNGbckBNadpPEaFtVgmqfj_output.jsonl\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded batches/batch_tasks_queries_1.jsonl\n",
      "Successfully loaded batches/batch_tasks_queries_2.jsonl\n",
      "Successfully loaded batches/batch_tasks_queries_3.jsonl\n",
      "Successfully loaded batches/batch_tasks_queries_4.jsonl\n",
      "Successfully loaded batches/batch_tasks_queries_5.jsonl\n",
      "Successfully loaded batches/batch_tasks_queries_6.jsonl\n",
      "Successfully loaded batches/batch_tasks_queries_7.jsonl\n",
      "Successfully loaded batches/batch_tasks_queries_8.jsonl\n",
      "Successfully loaded batches/batch_tasks_queries_9.jsonl\n",
      "Successfully loaded batches/batch_tasks_queries_10.jsonl\n",
      "Successfully loaded batches/batch_tasks_queries_11.jsonl\n",
      "Successfully loaded batches/batch_tasks_queries_12.jsonl\n",
      "Successfully loaded batches/batch_tasks_queries_13.jsonl\n",
      "Successfully loaded batches/batch_tasks_queries_14.jsonl\n",
      "Successfully loaded batches/batch_tasks_queries_15.jsonl\n",
      "Input Data Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>method</th>\n",
       "      <th>url</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>task-0</td>\n",
       "      <td>POST</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>{'model': 'gpt-4o-mini', 'messages': [{'role':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>task-1</td>\n",
       "      <td>POST</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>{'model': 'gpt-4o-mini', 'messages': [{'role':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>task-2</td>\n",
       "      <td>POST</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>{'model': 'gpt-4o-mini', 'messages': [{'role':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>task-3</td>\n",
       "      <td>POST</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>{'model': 'gpt-4o-mini', 'messages': [{'role':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>task-4</td>\n",
       "      <td>POST</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>{'model': 'gpt-4o-mini', 'messages': [{'role':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  custom_id method                   url  \\\n",
       "0    task-0   POST  /v1/chat/completions   \n",
       "1    task-1   POST  /v1/chat/completions   \n",
       "2    task-2   POST  /v1/chat/completions   \n",
       "3    task-3   POST  /v1/chat/completions   \n",
       "4    task-4   POST  /v1/chat/completions   \n",
       "\n",
       "                                                body  \n",
       "0  {'model': 'gpt-4o-mini', 'messages': [{'role':...  \n",
       "1  {'model': 'gpt-4o-mini', 'messages': [{'role':...  \n",
       "2  {'model': 'gpt-4o-mini', 'messages': [{'role':...  \n",
       "3  {'model': 'gpt-4o-mini', 'messages': [{'role':...  \n",
       "4  {'model': 'gpt-4o-mini', 'messages': [{'role':...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the input files one by one and concatenate the results\n",
    "input_data = read_files(input_file_names)\n",
    "print(\"Input Data Sample:\")\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded batches/outputs/1_batch_PoC7eDs9NQBh7fjeU24oPLbj_output.jsonl\n",
      "Successfully loaded batches/outputs/2_batch_TtqZkmGuJkvBiDMFlnfYrz26_output.jsonl\n",
      "Successfully loaded batches/outputs/3_batch_CD1D0C8yA7pD8B3Lii8hS80E_output.jsonl\n",
      "Successfully loaded batches/outputs/4_batch_zxAevbs0cwwEArQ6ehIhpxo2_output.jsonl\n",
      "Successfully loaded batches/outputs/5_batch_fmBtKML1oXWpEgt1Wwwe9tEf_output.jsonl\n",
      "Successfully loaded batches/outputs/6_batch_FWgAv510sVRhDmbwYquOtpnF_output.jsonl\n",
      "Successfully loaded batches/outputs/7_batch_Pj2nb7ICOeH3tDX044ZvyXeS_output.jsonl\n",
      "Successfully loaded batches/outputs/8_batch_KWDRxZD0l9HNeFIXeAShabFQ_output.jsonl\n",
      "Successfully loaded batches/outputs/9_batch_0MTrNU0cmxgodLvYKsXK8VON_output.jsonl\n",
      "Successfully loaded batches/outputs/10_batch_7g0csgkSanQPM2sE3EOTo9yc_output.jsonl\n",
      "Successfully loaded batches/outputs/11_batch_KOp7vbxMAYa6rXyYOizUfVel_output.jsonl\n",
      "Successfully loaded batches/outputs/12_batch_yMPPBChPtn5y3QcrhshpMH5O_output.jsonl\n",
      "Successfully loaded batches/outputs/13_batch_bpZzVjOPDXAxL8ISaKK2Bn1N_output.jsonl\n",
      "Successfully loaded batches/outputs/14_batch_oZREwstzByDley0gFHgPtIVp_output.jsonl\n",
      "Successfully loaded batches/outputs/15_batch_BFHNGbckBNadpPEaFtVgmqfj_output.jsonl\n",
      "Output Data Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>custom_id</th>\n",
       "      <th>response</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batch_req_8b6CbNmyCH9AO6gQbZUXmLsv</td>\n",
       "      <td>task-0</td>\n",
       "      <td>{'status_code': 200, 'request_id': '78de2c2333...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>batch_req_ifp4wcKyhaI7KRS2QR3nA0SD</td>\n",
       "      <td>task-1</td>\n",
       "      <td>{'status_code': 200, 'request_id': '75a7f0dfad...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batch_req_nzw0TlP3fAM60IF91dn4uGGH</td>\n",
       "      <td>task-2</td>\n",
       "      <td>{'status_code': 200, 'request_id': '1bf8565724...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>batch_req_45hEMH0HrF4L6ViY1W6LcW2t</td>\n",
       "      <td>task-3</td>\n",
       "      <td>{'status_code': 200, 'request_id': '0ee60a5eef...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>batch_req_YWrN2JqQalx0St8PJdKO349T</td>\n",
       "      <td>task-4</td>\n",
       "      <td>{'status_code': 200, 'request_id': 'e2c598d0c4...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id custom_id  \\\n",
       "0  batch_req_8b6CbNmyCH9AO6gQbZUXmLsv    task-0   \n",
       "1  batch_req_ifp4wcKyhaI7KRS2QR3nA0SD    task-1   \n",
       "2  batch_req_nzw0TlP3fAM60IF91dn4uGGH    task-2   \n",
       "3  batch_req_45hEMH0HrF4L6ViY1W6LcW2t    task-3   \n",
       "4  batch_req_YWrN2JqQalx0St8PJdKO349T    task-4   \n",
       "\n",
       "                                            response  error  \n",
       "0  {'status_code': 200, 'request_id': '78de2c2333...    NaN  \n",
       "1  {'status_code': 200, 'request_id': '75a7f0dfad...    NaN  \n",
       "2  {'status_code': 200, 'request_id': '1bf8565724...    NaN  \n",
       "3  {'status_code': 200, 'request_id': '0ee60a5eef...    NaN  \n",
       "4  {'status_code': 200, 'request_id': 'e2c598d0c4...    NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the output files one by one and concatenate the results\n",
    "output_data = read_files(output_file_names)\n",
    "print(\"Output Data Sample:\")\n",
    "output_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87083 entries, 0 to 87082\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   custom_id  87083 non-null  object\n",
      " 1   method     87083 non-null  object\n",
      " 2   url        87083 non-null  object\n",
      " 3   body       87083 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "input_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87083 entries, 0 to 87082\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   id         87083 non-null  object \n",
      " 1   custom_id  87083 non-null  object \n",
      " 2   response   87083 non-null  object \n",
      " 3   error      0 non-null      float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "output_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>original_answer</th>\n",
       "      <th>improved_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GROUNDNUT VERITIES</td>\n",
       "      <td>GROUNDNUT VERITIES -TAG 24 TG 26</td>\n",
       "      <td>groundnut varieties include tag 24 and tg 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASKED ABOUT SOWING TIME OF GROUND NUT</td>\n",
       "      <td>SOWING TIME OF GROUND NUT-IT GENERALLY CULTIVA...</td>\n",
       "      <td>the sowing time for groundnut is generally fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TELL ME CONTROL LAT IN GROUNDNUT</td>\n",
       "      <td>SPRAY OF PROFENOFOS 15 ML PER LITER WATER</td>\n",
       "      <td>the control of lat in groundnut involves the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weed management in groundnut</td>\n",
       "      <td>hand weeding</td>\n",
       "      <td>hand weeding is one of the most effective meth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Farmer wants to know about fungal disease mana...</td>\n",
       "      <td>--                -</td>\n",
       "      <td>fungal disease management in groundnut involve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                                 GROUNDNUT VERITIES   \n",
       "1              ASKED ABOUT SOWING TIME OF GROUND NUT   \n",
       "2                   TELL ME CONTROL LAT IN GROUNDNUT   \n",
       "3                       weed management in groundnut   \n",
       "4  Farmer wants to know about fungal disease mana...   \n",
       "\n",
       "                                     original_answer  \\\n",
       "0                   GROUNDNUT VERITIES -TAG 24 TG 26   \n",
       "1  SOWING TIME OF GROUND NUT-IT GENERALLY CULTIVA...   \n",
       "2          SPRAY OF PROFENOFOS 15 ML PER LITER WATER   \n",
       "3                                       hand weeding   \n",
       "4                                --                -   \n",
       "\n",
       "                                     improved_answer  \n",
       "0  groundnut varieties include tag 24 and tg 26, ...  \n",
       "1  the sowing time for groundnut is generally fro...  \n",
       "2  the control of lat in groundnut involves the s...  \n",
       "3  hand weeding is one of the most effective meth...  \n",
       "4  fungal disease management in groundnut involve...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to pair improved grammar answers back to their respective questions using custom_id\n",
    "def pair_questions_with_improved_answers(input_data, output_data):\n",
    "    qa_pairs = []\n",
    "    \n",
    "    # Create a dictionary for output data based on custom_id for faster lookups\n",
    "    output_dict = {item[\"custom_id\"]: item for item in output_data.to_dict(orient='records')}\n",
    "\n",
    "    # Iterate through the input data to match each question with its improved answer\n",
    "    for _, row in input_data.iterrows():\n",
    "        custom_id = row[\"custom_id\"]\n",
    "        \n",
    "        # Extract the question and original answer from the input data\n",
    "        question = row[\"body\"][\"messages\"][1][\"content\"].split(\"question '\")[1].split(\"',\")[0]\n",
    "        original_answer = row[\"body\"][\"messages\"][1][\"content\"].split(\"question: '\")[1].rstrip(\"'\")\n",
    "        \n",
    "        # Look up the corresponding improved answer in the output data\n",
    "        response_item = output_dict.get(custom_id, {})\n",
    "        \n",
    "        # If a valid response exists, extract the improved answer\n",
    "        if response_item and response_item.get(\"response\", {}).get(\"status_code\") == 200:\n",
    "            improved_answer = response_item[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "            qa_pairs.append({\n",
    "                \"question\": question,\n",
    "                \"original_answer\": original_answer,\n",
    "                \"improved_answer\": improved_answer\n",
    "            })\n",
    "    \n",
    "    # Convert the paired data into a DataFrame\n",
    "    return pd.DataFrame(qa_pairs)\n",
    "\n",
    "# Perform the pairing of questions with improved grammar answers\n",
    "paired_qa_df = pair_questions_with_improved_answers(input_data, output_data)\n",
    "\n",
    "# Display the first few rows of the paired questions and answers\n",
    "paired_qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/kcc_dataset_QA_cleaned_60K_grammar_improved.csv\n"
     ]
    }
   ],
   "source": [
    "print(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final dataset to a CSV file\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "paired_qa_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Step 1: Assume `paired_qa_df` is already available\n",
    "# If it isn't, you need to ensure it has columns: 'question', 'original_answer', 'improved_answer'\n",
    "\n",
    "# Step 2: Split the dataset into train, validation, and test sets\n",
    "train_df, temp_df = train_test_split(paired_qa_df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Step 3: Convert to Hugging Face datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Combine into a DatasetDict for easier management\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f84402a26ed40cf860a22f94b038abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/69666 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d22a704f2d400a8a88cf126dc77e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/8708 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eacdb7bf78645deb47baa5e1e6cefc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/8709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the dataset dict with the name 'kcc_dataset_grammar_improved'\n",
    "dataset_dict.save_to_disk(\"data/kcc_dataset_grammar_improved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee40be9c5b3448cfa03b011a5c154fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8264e9182d0c459289e89624fe25d879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/70 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d103f80f3b4faab63929b0e8992b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed88963fcfea4c5e8ef244c0ec07fca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be54542ca067457a93d0d01efe1719e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7992832d1e304bcd89bf02e7b2bcbc99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df872170d62496ab4936d9aca5aed0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/matovu-ronald/kisan_call_centre_groundnut_crop_QA_dataset_improved_grammar/commit/487017ad479845527479e56c9a06b31c92dfb7b8', commit_message='Upload dataset', commit_description='', oid='487017ad479845527479e56c9a06b31c92dfb7b8', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Push the dataset to the Hugging Face Hub\n",
    "# Replace 'your_dataset_name' with your desired dataset name\n",
    "# Replace 'your_username' with your Hugging Face username\n",
    "dataset_dict.push_to_hub(\"matovu-ronald/kisan_call_centre_groundnut_crop_QA_dataset_improved_grammar\", token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
